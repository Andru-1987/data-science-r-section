{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1350aff8",
   "metadata": {},
   "source": [
    "## MODELING AND PRE PROCESSING\n",
    "\n",
    "*Dado a todo lo investigado y conocer las relaciones que se ejercen directamente las features del dataset, podriamos usar las variables que mejor se nos ajuste, sin embargo, para seguir el mismo concepto de Quick & Dirty, vamos a hacer uso*\n",
    "\n",
    "Dividir los datos en **train / validation / test** para poder:\n",
    "\n",
    "* entrenar el modelo (`train`),\n",
    "* ajustar hiperpar√°metros (`validation`),\n",
    "* y evaluar el desempe√±o final (`test`).\n",
    "\n",
    "\n",
    "### Opciones\n",
    "\n",
    "* Si solo necesit√°s **train/test**, basta con un solo `train_test_split`.\n",
    "* Si vas a usar algo como **GridSearchCV o RandomizedSearchCV**, no necesit√°s `validation` expl√≠cito: esas clases ya hacen validaci√≥n cruzada.\n",
    "* Para problemas de **churn** (clasificaci√≥n con clases desbalanceadas) recomiendo **usar `stratify=y`** para que la proporci√≥n de churn/no-churn se mantenga igual en los splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173845a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "\n",
    "# setting display\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e99df6",
   "metadata": {},
   "source": [
    "## Obtener los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_sqlite_read(db_path, query, params=None):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        # Leer directamente a DataFrame\n",
    "        if params:\n",
    "            df = pd.read_sql_query(query, conn, params=params)\n",
    "        else:\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnDatabase:\n",
    "    \n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "        \n",
    "    def get_all_customers(self):\n",
    "        query = \"SELECT * FROM telco_customer_churn\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_churn_customers(self):\n",
    "        query = \"SELECT * FROM telco_customer_churn WHERE Churn = 'Yes'\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_customers_by_contract(self, contract_type):\n",
    "        query = \"SELECT * FROM telco_customer_churn WHERE Contract = ?\"\n",
    "        return pandas_sqlite_read(self.db_path, query, params=[contract_type])\n",
    "    \n",
    "    def get_high_value_customers(self, min_charges):\n",
    "        query = \"\"\"\n",
    "        SELECT customerID, gender, tenure, Contract, \n",
    "               MonthlyCharges, TotalCharges, Churn\n",
    "        FROM telco_customer_churn\n",
    "        WHERE TotalCharges > ?\n",
    "        ORDER BY TotalCharges DESC\n",
    "        \"\"\"\n",
    "        return pandas_sqlite_read(self.db_path, query, params=[min_charges])\n",
    "    \n",
    "    def get_churn_analysis_data(self):\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            gender,\n",
    "            SeniorCitizen,\n",
    "            Partner,\n",
    "            Dependents,\n",
    "            tenure,\n",
    "            PhoneService,\n",
    "            MultipleLines,\n",
    "            InternetService,\n",
    "            OnlineSecurity,\n",
    "            OnlineBackup,\n",
    "            DeviceProtection,\n",
    "            TechSupport,\n",
    "            StreamingTV,\n",
    "            StreamingMovies,\n",
    "            Contract,\n",
    "            PaperlessBilling,\n",
    "            PaymentMethod,\n",
    "            MonthlyCharges,\n",
    "            TotalCharges,\n",
    "            Churn = \"Yes\" AS Churn,\n",
    "            -- Features derivadas\n",
    "            CASE \n",
    "                WHEN tenure <= 12 THEN 'New'\n",
    "                WHEN tenure <= 36 THEN 'Regular' \n",
    "                ELSE 'Loyal'\n",
    "            END as customer_segment,\n",
    "            \n",
    "            CASE \n",
    "                WHEN MonthlyCharges < 35 THEN 'Low'\n",
    "                WHEN MonthlyCharges < 65 THEN 'Medium'\n",
    "                ELSE 'High'\n",
    "            END as price_segment,\n",
    "            \n",
    "            -- N√∫mero de servicios adicionales\n",
    "            (CASE WHEN OnlineSecurity = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN OnlineBackup = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN DeviceProtection = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN TechSupport = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN StreamingTV = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN StreamingMovies = 'Yes' THEN 1 ELSE 0 END) as additional_services\n",
    "             \n",
    "        FROM telco_customer_churn\n",
    "        \"\"\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_churn_summary_stats(self):\n",
    "\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            Contract,\n",
    "            PaymentMethod,\n",
    "            COUNT(*) as total_customers,\n",
    "            SUM(CASE WHEN Churn = 'Yes' THEN 1 ELSE 0 END) as churn_customers,\n",
    "            ROUND(\n",
    "                100.0 * SUM(CASE WHEN Churn = 'Yes' THEN 1 ELSE 0 END) / COUNT(*), \n",
    "                2\n",
    "            ) as churn_rate,\n",
    "            ROUND(AVG(MonthlyCharges), 2) as avg_monthly_charges,\n",
    "            ROUND(AVG(tenure), 2) as avg_tenure\n",
    "        FROM telco_customer_churn\n",
    "        GROUP BY Contract, PaymentMethod\n",
    "        ORDER BY churn_rate DESC\n",
    "        \"\"\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_dataframe_by_query(self, query:str):\n",
    "        return pandas_sqlite_read(self.db_path, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_objetct = ChurnDatabase(\"../database/telco_customer_churn.sqlite.db\")\n",
    "churn = churn_objetct.get_churn_analysis_data()\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afef7bc",
   "metadata": {},
   "source": [
    "## Pipe Modeling PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87609b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# --- Funci√≥n de limpieza global ---\n",
    "def clean_columns_global(df):\n",
    "    df = df.copy()\n",
    "    if \"PaymentMethod\" in df.columns:\n",
    "        df[\"PaymentMethod\"] = df[\"PaymentMethod\"].str.replace(r\" \\(automatic\\)\", \"\", regex=True)\n",
    "        \n",
    "    if \"TotalCharges\" in df.columns:\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].replace(\" \", np.nan).replace(\"\", np.nan)\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median())\n",
    "    return df\n",
    "\n",
    "# --- Transformadores globales ---\n",
    "mapper_columns_bins = {\"Yes\": 1, \"No\": 0, \"Male\": 1, \"Female\": 0}\n",
    "\n",
    "def map_bins(X): \n",
    "    return X.applymap(lambda x: mapper_columns_bins.get(x, x) if isinstance(x, str) else x)\n",
    "\n",
    "def to_numeric(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        df = pd.DataFrame(X)\n",
    "        return df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "    else:\n",
    "        return X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# --- Build preprocessor ---\n",
    "def build_preprocessor(X):\n",
    "    bin_transformer = FunctionTransformer(func=map_bins, validate=False)\n",
    "    numeric_transformer = FunctionTransformer(func=to_numeric, validate=False)\n",
    "\n",
    "    bin_cols = [\"gender\",\"Partner\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\",\"Churn\"]\n",
    "    ordinal_cols = [\"customer_segment\", \"price_segment\", \"additional_services\"]\n",
    "    num_cols = [\"tenure\", \"SeniorCitizen\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "    multi_cols_for_dummies = [\n",
    "        \"MultipleLines\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\n",
    "        \"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\n",
    "        \"Contract\",\"PaymentMethod\"\n",
    "    ]\n",
    "\n",
    "    ordinal_categories = [\n",
    "        [\"New\", \"Regular\", \"Loyal\"],  # customer_segment\n",
    "        [\"Low\", \"Medium\", \"High\"],    # price_segment\n",
    "        [0, 1, 2, 3, 4, 5, 6]        # additional_services\n",
    "    ]\n",
    "\n",
    "    ordinal_transformer = OrdinalEncoder(categories=ordinal_categories)\n",
    "    multi_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    scaling = StandardScaler()\n",
    "\n",
    "    # --- Filtrar columnas presentes ---\n",
    "    bin_cols_present = [c for c in bin_cols if c in X.columns]\n",
    "    ordinal_cols_present = [c for c in ordinal_cols if c in X.columns]\n",
    "    multi_cols_present = [c for c in multi_cols_for_dummies if c in X.columns]\n",
    "    num_cols_present = [c for c in num_cols if c in X.columns]\n",
    "\n",
    "    # --- ColumnTransformer ---\n",
    "    col_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"bin\", bin_transformer, bin_cols_present),\n",
    "            (\"ord\", ordinal_transformer, ordinal_cols_present),\n",
    "            (\"multi\", multi_transformer, multi_cols_present),\n",
    "            (\"scale\", scaling, num_cols_present),\n",
    "            (\"to_numeric\", numeric_transformer, X.columns)\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    return col_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "def train_single_model( X, y, balance=True, with_model = True, model= None):\n",
    "\n",
    "    steps = []\n",
    "    \n",
    "    # --- Preprocessor ---\n",
    "    preprocessor = build_preprocessor(X)\n",
    "    steps.append((\"preprocessor\", preprocessor))\n",
    "    \n",
    "    # --- Balanceo ---\n",
    "    if balance:\n",
    "        steps.append((\"balance\", SMOTETomek(random_state=42)))\n",
    "    \n",
    "    if with_model:\n",
    "        # --- Modelo ---\n",
    "        steps.append((\"model\", model))\n",
    "        \n",
    "    # --- Pipeline ---\n",
    "    pipe = ImbPipeline(steps=steps)\n",
    "    \n",
    "        # --- Cross-validation ---\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        pipe,\n",
    "        X, y,\n",
    "        cv=skf,\n",
    "        scoring=['accuracy', 'f1', 'roc_auc'],\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # --- Calcular medias ---\n",
    "    mean_scores = {key: np.mean(val) for key, val in scores.items()}\n",
    "    \n",
    "    print(\"Media de scores CV \")\n",
    "    for key, val in mean_scores.items():\n",
    "        print(f\"{key}: {val:.4f}\")\n",
    "    \n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135378d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_transformed_df(pipe, df: pd.DataFrame, target=\"Churn\"):\n",
    "    \"\"\"\n",
    "    Reconstruye un DataFrame transformado desde un pipeline entrenado,\n",
    "    preservando nombres de columnas para cada tipo de transformador.\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target])\n",
    "    \n",
    "    preprocessor = pipe.named_steps[\"preprocessor\"]\n",
    "    \n",
    "    transformed = preprocessor.transform(X)\n",
    "    # Si es sparse (por OneHot), convertir a array\n",
    "    if hasattr(transformed, \"toarray\"):\n",
    "        transformed = transformed.toarray()\n",
    "    \n",
    "    # --- Nombres de columnas ---\n",
    "    all_features = []\n",
    "\n",
    "    # Binarias\n",
    "    bin_cols = [c for c in [\"gender\",\"Partner\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\"] if c in X.columns]\n",
    "    all_features += bin_cols\n",
    "\n",
    "    # Ordinal\n",
    "    ordinal_cols = [c for c in [\"customer_segment\", \"price_segment\", \"additional_services\"] if c in X.columns]\n",
    "    all_features += ordinal_cols\n",
    "\n",
    "    # One-hot\n",
    "    multi_cols = [c for c in [\n",
    "        \"MultipleLines\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\n",
    "        \"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\n",
    "        \"Contract\",\"PaymentMethod\"] if c in X.columns]\n",
    "\n",
    "    if \"multi\" in preprocessor.named_transformers_:\n",
    "        onehot_cols = preprocessor.named_transformers_[\"multi\"].get_feature_names_out(multi_cols)\n",
    "        all_features += list(onehot_cols)\n",
    "\n",
    "    # Num√©ricas\n",
    "    num_cols = [c for c in [\"tenure\", \"SeniorCitizen\", \"MonthlyCharges\", \"TotalCharges\"] if c in X.columns]\n",
    "    all_features += num_cols\n",
    "\n",
    "    # Si el array tiene m√°s columnas que nombres, generar nombres gen√©ricos\n",
    "    if transformed.shape[1] > len(all_features):\n",
    "        extra_cols = transformed.shape[1] - len(all_features)\n",
    "        all_features += [f\"extra_{i}\" for i in range(extra_cols)]\n",
    "\n",
    "    return pd.DataFrame(transformed, columns=all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funci√≥n para evaluar modelos entrenados ---\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "def evaluate_models(trained_models, X, y):\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in trained_models.items():\n",
    "        result = eval_model(model, X, y)\n",
    "        results[name] = result\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "def eval_model(model, X, y):\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y, y_pred),\n",
    "        \"precision\": precision_score(y, y_pred),\n",
    "        \"recall\": recall_score(y, y_pred),\n",
    "        \"f1\": f1_score(y, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y, y_proba),\n",
    "        \"pr_auc\": average_precision_score(y, y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80267a5f",
   "metadata": {},
   "source": [
    "## Split Train Validation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc2da7",
   "metadata": {},
   "source": [
    "* `SMOTE` ‚Üí genera nuevas muestras **sint√©ticas** para la clase minoritaria.\n",
    "* `TomekLinks` ‚Üí elimina ejemplos de la clase mayoritaria que est√°n muy cerca de la minoritaria (ruido/solapamiento).\n",
    "* `SMOTETomek` ‚Üí combina ambos pasos en una sola estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Data split\n",
    "\n",
    "churn = clean_columns_global(churn)\n",
    "\n",
    "# Supongamos que ya ten√©s X (features) y y (target)\n",
    "X = churn.drop(\"Churn\", axis=1)\n",
    "y = churn[\"Churn\"]\n",
    "\n",
    "# Primero separamos train+val vs test (20% para test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#  Luego de train+val, volvemos a separar: train (60%), val (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    ")\n",
    "# (0.25 de 0.8 = 0.20 ‚Üí o sea: 60% train, 20% val, 20% test)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "print(X_train.columns)\n",
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, roc_auc_score, average_precision_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Definimos folds estratificados\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelos baseline\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",   # ajusta peso de clases\n",
    "        penalty=\"l2\",              # regularizaci√≥n L2 para evitar overfitting\n",
    "        C=0.1,                     # regularizaci√≥n m√°s fuerte (menor C = m√°s regularizaci√≥n)\n",
    "        solver=\"liblinear\",        # bueno para datasets peque√±os/medianos\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced_subsample',\n",
    "        bootstrap=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LightGBM\":LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=100\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15efc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pipes = {\n",
    "    name:train_single_model(X=X_train, y=y_train, model=model)\n",
    "    for name,model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "validacion = evaluate_models(models_pipes, X_train_val, y_train_val)\n",
    "validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = evaluate_models(models_pipes, X_test, y_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric_differences(eval_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    diff_df = eval_df.set_index(eval_df.index) - test_df.set_index(test_df.index)\n",
    "    diff_df = diff_df.rename(columns=lambda c: f\"{c}_diff\")\n",
    "    return diff_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6026b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metric_differences(validacion,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30225a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def plot_metric_differences(eval_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    # Calculamos diferencias\n",
    "    diff_df = eval_df.set_index(eval_df.index) - test_df.set_index(test_df.index)\n",
    "    diff_df = diff_df.rename(columns=lambda c: f\"{c}_diff\")\n",
    "    \n",
    "    # Convertimos a formato largo para Plotly\n",
    "    diff_long = diff_df.reset_index().melt(id_vars='index', var_name='Metric', value_name='Difference')\n",
    "    \n",
    "    # Creamos gr√°fico de barras\n",
    "    fig = px.bar(diff_long, x='index', y='Difference', color='Metric', barmode='group',\n",
    "                 title=\"Diferencias entre m√©tricas de evaluaci√≥n y test\",\n",
    "                 labels={'index':'Modelo'})\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "    fig = px.imshow(\n",
    "        diff_df,\n",
    "        text_auto=True,\n",
    "        color_continuous_scale='RdYlGn_r',  # rojo = mayor diferencia, verde = menor\n",
    "        aspect=\"auto\",\n",
    "        labels=dict(x=\"M√©trica\", y=\"Modelo\", color=\"Diferencia\"),\n",
    "        title=\"Heatmap de diferencias entre m√©tricas de evaluaci√≥n y test\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ad945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_differences(validacion,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60f864",
   "metadata": {},
   "source": [
    "## Metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "def plot_model_comparison(trained_models, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Genera un subplot con:\n",
    "      - Curvas ROC para validation y test de cada modelo\n",
    "      - Matriz de confusi√≥n para validation y test de cada modelo\n",
    "\n",
    "    Args:\n",
    "        trained_models (dict): Diccionario {nombre_modelo: modelo_entrenado}\n",
    "        X_val, y_val: Dataset de validaci√≥n\n",
    "        X_test, y_test: Dataset de test\n",
    "    \"\"\"\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    n_models = len(trained_models)\n",
    "\n",
    "    subplot_titles = [title for name in trained_models.keys() for title in \n",
    "                  [f\"{name} ROC Val\", f\"{name} ROC Test\", f\"{name} CM Val\", f\"{name} CM Test\"]]\n",
    "\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_models, cols=4,\n",
    "        subplot_titles= subplot_titles,\n",
    "        horizontal_spacing=0.1,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "\n",
    "    row = 1\n",
    "    for model_name, model in trained_models.items():\n",
    "        # --- Curvas ROC ---\n",
    "        for col, (X, y, label) in enumerate([(X_val, y_val, 'Val'), (X_test, y_test, 'Test')], start=1):\n",
    "            y_proba = model.predict_proba(X)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=fpr, y=tpr, mode='lines', name=f\"{model_name} {label} (AUC={roc_auc:.2f})\"),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.update_xaxes(title_text=\"FPR\", row=row, col=col)\n",
    "            fig.update_yaxes(title_text=\"TPR\", row=row, col=col)\n",
    "\n",
    "        # --- Matrices de Confusi√≥n ---\n",
    "        for col, (X, y, label) in enumerate([(X_val, y_val, 'Val'), (X_test, y_test, 'Test')], start=3):\n",
    "            y_pred = model.predict(X)\n",
    "            cm = confusion_matrix(y, y_pred)\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=cm,\n",
    "                    x=[f\"Pred {c}\" for c in range(cm.shape[1])],\n",
    "                    y=[f\"True {c}\" for c in range(cm.shape[0])],\n",
    "                    showscale=False,\n",
    "                    colorscale='Blues',\n",
    "                    text=cm,\n",
    "                    texttemplate=\"%{text}\"\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "        row += 1\n",
    "\n",
    "    fig.update_layout(height=300*n_models, width=1400, title_text=\"Comparaci√≥n de Modelos: ROC y Matriz de Confusi√≥n\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_comparison(\n",
    "    models_pipes,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ce6af",
   "metadata": {},
   "source": [
    "## Guardado de Modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc98c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def save_model_with_score(model, model_name, X_test, y_test, folder=\"../models\"):\n",
    "    \"\"\"\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    model : estimator\n",
    "        Modelo ya entrenado (fit).\n",
    "    X_test : DataFrame o array\n",
    "        Datos de test para evaluar.\n",
    "    y_test : Series o array\n",
    "        Etiquetas verdaderas.\n",
    "    filename : str\n",
    "        Nombre del archivo .pkl donde se guardar√° el modelo.\n",
    "    metrics : list\n",
    "        Lista de m√©tricas a calcular, ej: [\"accuracy\", \"f1\", \"precision\", \"recall\"].\n",
    "    folder : str\n",
    "        Carpeta donde se guardar√° el modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    scores = eval_model(model, X_test, y_test)\n",
    "    \n",
    "    # Extraer nombres de columnas si es DataFrame\n",
    "    if hasattr(X_test, \"columns\"):\n",
    "        feature_names = list(X_test.columns)\n",
    "    else:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X_test.shape[1])]\n",
    "\n",
    "\n",
    "    # Guardar con joblib\n",
    "    _name = model_name.split(\" \")\n",
    "    _name = \"_\".join(_name).lower() + \".pkl\"\n",
    "\n",
    "    # Empaquetar modelo + scores + columnas\n",
    "    obj_to_save = {\n",
    "        \"name\": model_name,\n",
    "        \"model\": model,\n",
    "        \"scores\": scores,\n",
    "        \"features\": feature_names\n",
    "    }\n",
    "    \n",
    "    filepath = os.path.join(folder, _name)\n",
    "    joblib.dump(obj_to_save, filepath)\n",
    "\n",
    "    print(f\"‚úÖ Modelo guardado en {filepath} con scores: {scores}\")\n",
    "    print(f\"üìå Columnas guardadas: {feature_names}\")\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aae677",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,model in models_pipes.items():\n",
    "    print(f\"Guardando el modelo: {name}\")\n",
    "    save_model_with_score(model,name,X_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
