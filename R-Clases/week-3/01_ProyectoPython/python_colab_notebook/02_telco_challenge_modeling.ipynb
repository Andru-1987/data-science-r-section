{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1350aff8",
   "metadata": {},
   "source": [
    "## MODELING AND PRE PROCESSING\n",
    "\n",
    "*Dado a todo lo investigado y conocer las relaciones que se ejercen directamente las features del dataset, podriamos usar las variables que mejor se nos ajuste, sin embargo, para seguir el mismo concepto de Quick & Dirty, vamos a hacer uso*\n",
    "\n",
    "Dividir los datos en **train / validation / test** para poder:\n",
    "\n",
    "* entrenar el modelo (`train`),\n",
    "* ajustar hiperparámetros (`validation`),\n",
    "* y evaluar el desempeño final (`test`).\n",
    "\n",
    "\n",
    "### Opciones\n",
    "\n",
    "* Si solo necesitás **train/test**, basta con un solo `train_test_split`.\n",
    "* Si vas a usar algo como **GridSearchCV o RandomizedSearchCV**, no necesitás `validation` explícito: esas clases ya hacen validación cruzada.\n",
    "* Para problemas de **churn** (clasificación con clases desbalanceadas) recomiendo **usar `stratify=y`** para que la proporción de churn/no-churn se mantenga igual en los splits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173845a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "\n",
    "# setting display\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e99df6",
   "metadata": {},
   "source": [
    "## Obtener los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_sqlite_read(db_path, query, params=None):\n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        # Leer directamente a DataFrame\n",
    "        if params:\n",
    "            df = pd.read_sql_query(query, conn, params=params)\n",
    "        else:\n",
    "            df = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnDatabase:\n",
    "    \n",
    "    def __init__(self, db_path):\n",
    "        self.db_path = db_path\n",
    "        \n",
    "    def get_all_customers(self):\n",
    "        query = \"SELECT * FROM telco_customer_churn\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_churn_customers(self):\n",
    "        query = \"SELECT * FROM telco_customer_churn WHERE Churn = 'Yes'\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_customers_by_contract(self, contract_type):\n",
    "        query = \"SELECT * FROM telco_customer_churn WHERE Contract = ?\"\n",
    "        return pandas_sqlite_read(self.db_path, query, params=[contract_type])\n",
    "    \n",
    "    def get_high_value_customers(self, min_charges):\n",
    "        query = \"\"\"\n",
    "        SELECT customerID, gender, tenure, Contract, \n",
    "               MonthlyCharges, TotalCharges, Churn\n",
    "        FROM telco_customer_churn\n",
    "        WHERE TotalCharges > ?\n",
    "        ORDER BY TotalCharges DESC\n",
    "        \"\"\"\n",
    "        return pandas_sqlite_read(self.db_path, query, params=[min_charges])\n",
    "    \n",
    "    def get_churn_analysis_data(self):\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            gender,\n",
    "            SeniorCitizen,\n",
    "            Partner,\n",
    "            Dependents,\n",
    "            tenure,\n",
    "            PhoneService,\n",
    "            MultipleLines,\n",
    "            InternetService,\n",
    "            OnlineSecurity,\n",
    "            OnlineBackup,\n",
    "            DeviceProtection,\n",
    "            TechSupport,\n",
    "            StreamingTV,\n",
    "            StreamingMovies,\n",
    "            Contract,\n",
    "            PaperlessBilling,\n",
    "            PaymentMethod,\n",
    "            MonthlyCharges,\n",
    "            TotalCharges,\n",
    "            Churn = \"Yes\" AS Churn,\n",
    "            -- Features derivadas\n",
    "            CASE \n",
    "                WHEN tenure <= 12 THEN 'New'\n",
    "                WHEN tenure <= 36 THEN 'Regular' \n",
    "                ELSE 'Loyal'\n",
    "            END as customer_segment,\n",
    "            \n",
    "            CASE \n",
    "                WHEN MonthlyCharges < 35 THEN 'Low'\n",
    "                WHEN MonthlyCharges < 65 THEN 'Medium'\n",
    "                ELSE 'High'\n",
    "            END as price_segment,\n",
    "            \n",
    "            -- Número de servicios adicionales\n",
    "            (CASE WHEN OnlineSecurity = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN OnlineBackup = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN DeviceProtection = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN TechSupport = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN StreamingTV = 'Yes' THEN 1 ELSE 0 END +\n",
    "             CASE WHEN StreamingMovies = 'Yes' THEN 1 ELSE 0 END) as additional_services\n",
    "             \n",
    "        FROM telco_customer_churn\n",
    "        \"\"\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_churn_summary_stats(self):\n",
    "\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            Contract,\n",
    "            PaymentMethod,\n",
    "            COUNT(*) as total_customers,\n",
    "            SUM(CASE WHEN Churn = 'Yes' THEN 1 ELSE 0 END) as churn_customers,\n",
    "            ROUND(\n",
    "                100.0 * SUM(CASE WHEN Churn = 'Yes' THEN 1 ELSE 0 END) / COUNT(*), \n",
    "                2\n",
    "            ) as churn_rate,\n",
    "            ROUND(AVG(MonthlyCharges), 2) as avg_monthly_charges,\n",
    "            ROUND(AVG(tenure), 2) as avg_tenure\n",
    "        FROM telco_customer_churn\n",
    "        GROUP BY Contract, PaymentMethod\n",
    "        ORDER BY churn_rate DESC\n",
    "        \"\"\"\n",
    "        return pandas_sqlite_read(self.db_path, query)\n",
    "    \n",
    "    def get_dataframe_by_query(self, query:str):\n",
    "        return pandas_sqlite_read(self.db_path, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_objetct = ChurnDatabase(\"../database/telco_customer_churn.sqlite.db\")\n",
    "churn = churn_objetct.get_churn_analysis_data()\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afef7bc",
   "metadata": {},
   "source": [
    "## Pipe Modeling PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87609b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# --- Función de limpieza global ---\n",
    "def clean_columns_global(df):\n",
    "    df = df.copy()\n",
    "    if \"PaymentMethod\" in df.columns:\n",
    "        df[\"PaymentMethod\"] = df[\"PaymentMethod\"].str.replace(r\" \\(automatic\\)\", \"\", regex=True)\n",
    "        \n",
    "    if \"TotalCharges\" in df.columns:\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].replace(\" \", np.nan).replace(\"\", np.nan)\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)\n",
    "        df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].median())\n",
    "    return df\n",
    "\n",
    "# --- Transformadores globales ---\n",
    "mapper_columns_bins = {\"Yes\": 1, \"No\": 0, \"Male\": 1, \"Female\": 0}\n",
    "\n",
    "def map_bins(X): \n",
    "    return X.applymap(lambda x: mapper_columns_bins.get(x, x) if isinstance(x, str) else x)\n",
    "\n",
    "def to_numeric(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        df = pd.DataFrame(X)\n",
    "        return df.apply(pd.to_numeric, errors='coerce').fillna(0).values\n",
    "    else:\n",
    "        return X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# --- Build preprocessor ---\n",
    "def build_preprocessor(X):\n",
    "    bin_transformer = FunctionTransformer(func=map_bins, validate=False)\n",
    "    numeric_transformer = FunctionTransformer(func=to_numeric, validate=False)\n",
    "\n",
    "    bin_cols = [\"gender\",\"Partner\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\",\"Churn\"]\n",
    "    ordinal_cols = [\"customer_segment\", \"price_segment\", \"additional_services\"]\n",
    "    num_cols = [\"tenure\", \"SeniorCitizen\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "    multi_cols_for_dummies = [\n",
    "        \"MultipleLines\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\n",
    "        \"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\n",
    "        \"Contract\",\"PaymentMethod\"\n",
    "    ]\n",
    "\n",
    "    ordinal_categories = [\n",
    "        [\"New\", \"Regular\", \"Loyal\"],  # customer_segment\n",
    "        [\"Low\", \"Medium\", \"High\"],    # price_segment\n",
    "        [0, 1, 2, 3, 4, 5, 6]        # additional_services\n",
    "    ]\n",
    "\n",
    "    ordinal_transformer = OrdinalEncoder(categories=ordinal_categories)\n",
    "    multi_transformer = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    scaling = StandardScaler()\n",
    "\n",
    "    # --- Filtrar columnas presentes ---\n",
    "    bin_cols_present = [c for c in bin_cols if c in X.columns]\n",
    "    ordinal_cols_present = [c for c in ordinal_cols if c in X.columns]\n",
    "    multi_cols_present = [c for c in multi_cols_for_dummies if c in X.columns]\n",
    "    num_cols_present = [c for c in num_cols if c in X.columns]\n",
    "\n",
    "    # --- ColumnTransformer ---\n",
    "    col_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"bin\", bin_transformer, bin_cols_present),\n",
    "            (\"ord\", ordinal_transformer, ordinal_cols_present),\n",
    "            (\"multi\", multi_transformer, multi_cols_present),\n",
    "            (\"scale\", scaling, num_cols_present),\n",
    "            (\"to_numeric\", numeric_transformer, X.columns)\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    return col_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "def train_single_model( X, y, balance=True, with_model = True, model= None):\n",
    "\n",
    "    steps = []\n",
    "    \n",
    "    # --- Preprocessor ---\n",
    "    preprocessor = build_preprocessor(X)\n",
    "    steps.append((\"preprocessor\", preprocessor))\n",
    "    \n",
    "    # --- Balanceo ---\n",
    "    if balance:\n",
    "        steps.append((\"balance\", SMOTETomek(random_state=42)))\n",
    "    \n",
    "    if with_model:\n",
    "        # --- Modelo ---\n",
    "        steps.append((\"model\", model))\n",
    "        \n",
    "    # --- Pipeline ---\n",
    "    pipe = ImbPipeline(steps=steps)\n",
    "    \n",
    "        # --- Cross-validation ---\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        pipe,\n",
    "        X, y,\n",
    "        cv=skf,\n",
    "        scoring=['accuracy', 'f1', 'roc_auc'],\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # --- Calcular medias ---\n",
    "    mean_scores = {key: np.mean(val) for key, val in scores.items()}\n",
    "    \n",
    "    print(\"Media de scores CV \")\n",
    "    for key, val in mean_scores.items():\n",
    "        print(f\"{key}: {val:.4f}\")\n",
    "    \n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135378d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_transformed_df(pipe, df: pd.DataFrame, target=\"Churn\"):\n",
    "    \"\"\"\n",
    "    Reconstruye un DataFrame transformado desde un pipeline entrenado,\n",
    "    preservando nombres de columnas para cada tipo de transformador.\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target])\n",
    "    \n",
    "    preprocessor = pipe.named_steps[\"preprocessor\"]\n",
    "    \n",
    "    transformed = preprocessor.transform(X)\n",
    "    # Si es sparse (por OneHot), convertir a array\n",
    "    if hasattr(transformed, \"toarray\"):\n",
    "        transformed = transformed.toarray()\n",
    "    \n",
    "    # --- Nombres de columnas ---\n",
    "    all_features = []\n",
    "\n",
    "    # Binarias\n",
    "    bin_cols = [c for c in [\"gender\",\"Partner\",\"Dependents\",\"PhoneService\",\"PaperlessBilling\"] if c in X.columns]\n",
    "    all_features += bin_cols\n",
    "\n",
    "    # Ordinal\n",
    "    ordinal_cols = [c for c in [\"customer_segment\", \"price_segment\", \"additional_services\"] if c in X.columns]\n",
    "    all_features += ordinal_cols\n",
    "\n",
    "    # One-hot\n",
    "    multi_cols = [c for c in [\n",
    "        \"MultipleLines\",\"InternetService\",\"OnlineSecurity\",\"OnlineBackup\",\n",
    "        \"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\",\n",
    "        \"Contract\",\"PaymentMethod\"] if c in X.columns]\n",
    "\n",
    "    if \"multi\" in preprocessor.named_transformers_:\n",
    "        onehot_cols = preprocessor.named_transformers_[\"multi\"].get_feature_names_out(multi_cols)\n",
    "        all_features += list(onehot_cols)\n",
    "\n",
    "    # Numéricas\n",
    "    num_cols = [c for c in [\"tenure\", \"SeniorCitizen\", \"MonthlyCharges\", \"TotalCharges\"] if c in X.columns]\n",
    "    all_features += num_cols\n",
    "\n",
    "    # Si el array tiene más columnas que nombres, generar nombres genéricos\n",
    "    if transformed.shape[1] > len(all_features):\n",
    "        extra_cols = transformed.shape[1] - len(all_features)\n",
    "        all_features += [f\"extra_{i}\" for i in range(extra_cols)]\n",
    "\n",
    "    return pd.DataFrame(transformed, columns=all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2dd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para evaluar modelos entrenados ---\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "def evaluate_models(trained_models, X, y):\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in trained_models.items():\n",
    "        result = eval_model(model, X, y)\n",
    "        results[name] = result\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "def eval_model(model, X, y):\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y, y_pred),\n",
    "        \"precision\": precision_score(y, y_pred),\n",
    "        \"recall\": recall_score(y, y_pred),\n",
    "        \"f1\": f1_score(y, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y, y_proba),\n",
    "        \"pr_auc\": average_precision_score(y, y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80267a5f",
   "metadata": {},
   "source": [
    "## Split Train Validation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc2da7",
   "metadata": {},
   "source": [
    "* `SMOTE` → genera nuevas muestras **sintéticas** para la clase minoritaria.\n",
    "* `TomekLinks` → elimina ejemplos de la clase mayoritaria que están muy cerca de la minoritaria (ruido/solapamiento).\n",
    "* `SMOTETomek` → combina ambos pasos en una sola estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Data split\n",
    "\n",
    "churn = clean_columns_global(churn)\n",
    "\n",
    "# Supongamos que ya tenés X (features) y y (target)\n",
    "X = churn.drop(\"Churn\", axis=1)\n",
    "y = churn[\"Churn\"]\n",
    "\n",
    "# Primero separamos train+val vs test (20% para test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#  Luego de train+val, volvemos a separar: train (60%), val (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    ")\n",
    "# (0.25 de 0.8 = 0.20 → o sea: 60% train, 20% val, 20% test)\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation:\", X_val.shape, y_val.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)\n",
    "\n",
    "print(X_train.columns)\n",
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score, precision_score, roc_auc_score, average_precision_score\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Definimos folds estratificados\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelos baseline\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",   # ajusta peso de clases\n",
    "        penalty=\"l2\",              # regularización L2 para evitar overfitting\n",
    "        C=0.1,                     # regularización más fuerte (menor C = más regularización)\n",
    "        solver=\"liblinear\",        # bueno para datasets pequeños/medianos\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced_subsample',\n",
    "        bootstrap=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LightGBM\":LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=100\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15efc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pipes = {\n",
    "    name:train_single_model(X=X_train, y=y_train, model=model)\n",
    "    for name,model in models.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "validacion = evaluate_models(models_pipes, X_train_val, y_train_val)\n",
    "validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = evaluate_models(models_pipes, X_test, y_test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metric_differences(eval_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    diff_df = eval_df.set_index(eval_df.index) - test_df.set_index(test_df.index)\n",
    "    diff_df = diff_df.rename(columns=lambda c: f\"{c}_diff\")\n",
    "    return diff_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6026b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metric_differences(validacion,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30225a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "def plot_metric_differences(eval_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    # Calculamos diferencias\n",
    "    diff_df = eval_df.set_index(eval_df.index) - test_df.set_index(test_df.index)\n",
    "    diff_df = diff_df.rename(columns=lambda c: f\"{c}_diff\")\n",
    "    \n",
    "    # Convertimos a formato largo para Plotly\n",
    "    diff_long = diff_df.reset_index().melt(id_vars='index', var_name='Metric', value_name='Difference')\n",
    "    \n",
    "    # Creamos gráfico de barras\n",
    "    fig = px.bar(diff_long, x='index', y='Difference', color='Metric', barmode='group',\n",
    "                 title=\"Diferencias entre métricas de evaluación y test\",\n",
    "                 labels={'index':'Modelo'})\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "    fig = px.imshow(\n",
    "        diff_df,\n",
    "        text_auto=True,\n",
    "        color_continuous_scale='RdYlGn_r',  # rojo = mayor diferencia, verde = menor\n",
    "        aspect=\"auto\",\n",
    "        labels=dict(x=\"Métrica\", y=\"Modelo\", color=\"Diferencia\"),\n",
    "        title=\"Heatmap de diferencias entre métricas de evaluación y test\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ad945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_differences(validacion,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60f864",
   "metadata": {},
   "source": [
    "## Metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "def plot_model_comparison(trained_models, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Genera un subplot con:\n",
    "      - Curvas ROC para validation y test de cada modelo\n",
    "      - Matriz de confusión para validation y test de cada modelo\n",
    "\n",
    "    Args:\n",
    "        trained_models (dict): Diccionario {nombre_modelo: modelo_entrenado}\n",
    "        X_val, y_val: Dataset de validación\n",
    "        X_test, y_test: Dataset de test\n",
    "    \"\"\"\n",
    "    from plotly.subplots import make_subplots\n",
    "    \n",
    "    n_models = len(trained_models)\n",
    "\n",
    "    subplot_titles = [title for name in trained_models.keys() for title in \n",
    "                  [f\"{name} ROC Val\", f\"{name} ROC Test\", f\"{name} CM Val\", f\"{name} CM Test\"]]\n",
    "\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=n_models, cols=4,\n",
    "        subplot_titles= subplot_titles,\n",
    "        horizontal_spacing=0.1,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "\n",
    "    row = 1\n",
    "    for model_name, model in trained_models.items():\n",
    "        # --- Curvas ROC ---\n",
    "        for col, (X, y, label) in enumerate([(X_val, y_val, 'Val'), (X_test, y_test, 'Test')], start=1):\n",
    "            y_proba = model.predict_proba(X)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y, y_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=fpr, y=tpr, mode='lines', name=f\"{model_name} {label} (AUC={roc_auc:.2f})\"),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            fig.update_xaxes(title_text=\"FPR\", row=row, col=col)\n",
    "            fig.update_yaxes(title_text=\"TPR\", row=row, col=col)\n",
    "\n",
    "        # --- Matrices de Confusión ---\n",
    "        for col, (X, y, label) in enumerate([(X_val, y_val, 'Val'), (X_test, y_test, 'Test')], start=3):\n",
    "            y_pred = model.predict(X)\n",
    "            cm = confusion_matrix(y, y_pred)\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=cm,\n",
    "                    x=[f\"Pred {c}\" for c in range(cm.shape[1])],\n",
    "                    y=[f\"True {c}\" for c in range(cm.shape[0])],\n",
    "                    showscale=False,\n",
    "                    colorscale='Blues',\n",
    "                    text=cm,\n",
    "                    texttemplate=\"%{text}\"\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "        row += 1\n",
    "\n",
    "    fig.update_layout(height=300*n_models, width=1400, title_text=\"Comparación de Modelos: ROC y Matriz de Confusión\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443a1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_comparison(\n",
    "    models_pipes,\n",
    "    X_val, y_val,\n",
    "    X_test, y_test\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ce6af",
   "metadata": {},
   "source": [
    "## Guardado de Modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc98c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def save_model_with_score(model, model_name, X_test, y_test, folder=\"../models\"):\n",
    "    \"\"\"\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    model : estimator\n",
    "        Modelo ya entrenado (fit).\n",
    "    X_test : DataFrame o array\n",
    "        Datos de test para evaluar.\n",
    "    y_test : Series o array\n",
    "        Etiquetas verdaderas.\n",
    "    filename : str\n",
    "        Nombre del archivo .pkl donde se guardará el modelo.\n",
    "    metrics : list\n",
    "        Lista de métricas a calcular, ej: [\"accuracy\", \"f1\", \"precision\", \"recall\"].\n",
    "    folder : str\n",
    "        Carpeta donde se guardará el modelo.\n",
    "    \"\"\"\n",
    "\n",
    "    # Crear carpeta si no existe\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Predecir\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    # Calcular métricas\n",
    "    scores = eval_model(model, X_test, y_test)\n",
    "    \n",
    "    # Extraer nombres de columnas si es DataFrame\n",
    "    if hasattr(X_test, \"columns\"):\n",
    "        feature_names = list(X_test.columns)\n",
    "    else:\n",
    "        feature_names = [f\"feature_{i}\" for i in range(X_test.shape[1])]\n",
    "\n",
    "\n",
    "    # Guardar con joblib\n",
    "    _name = model_name.split(\" \")\n",
    "    _name = \"_\".join(_name).lower() + \".pkl\"\n",
    "\n",
    "    # Empaquetar modelo + scores + columnas\n",
    "    obj_to_save = {\n",
    "        \"name\": model_name,\n",
    "        \"model\": model,\n",
    "        \"scores\": scores,\n",
    "        \"features\": feature_names\n",
    "    }\n",
    "    \n",
    "    filepath = os.path.join(folder, _name)\n",
    "    joblib.dump(obj_to_save, filepath)\n",
    "\n",
    "    print(f\"✅ Modelo guardado en {filepath} con scores: {scores}\")\n",
    "    print(f\"📌 Columnas guardadas: {feature_names}\")\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aae677",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,model in models_pipes.items():\n",
    "    print(f\"Guardando el modelo: {name}\")\n",
    "    save_model_with_score(model,name,X_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
