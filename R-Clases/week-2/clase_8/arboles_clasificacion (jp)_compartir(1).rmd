---
title: "Arboles de decisi√≥n con R - Clasificaci√≥n"
author: "Julio Paredes"
output: 
  html_document: 
    df_print: tibble
    fig_height: 7.5
    fig_width: 7.5
    highlight: tango
    theme: yeti
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

üå≥ Implementaci√≥n de √Årboles de Decisi√≥n en R üå≥

En este clase, exploraremos c√≥mo implementar √°rboles de decisi√≥n en R utilizando el paquete rpart. Descubrir√°s los fundamentos de los √°rboles de clasificaci√≥n, junto con algunos problemas comunes al procesar datos en R. ¬°Empecemos!

**Introducci√≥n a los √Årboles de Decisi√≥n**

Los √°rboles de decisi√≥n son como diagramas de flujo utilizados para predecir resultados en diferentes disciplinas. En aprendizaje autom√°tico, empleamos la t√©cnica CART (Classification And Regression Trees), una forma de aprendizaje supervisado donde buscamos una funci√≥n que prediga la variable objetivo basada en variables predictoras.

**Implementaci√≥n con RPART**

Usaremos RPART (Recursive Partitioning and Regression Trees), una implementaci√≥n espec√≠fica de CART. Este algoritmo busca la mejor separaci√≥n de datos en grupos utilizando reglas, formando nodos y hojas en un √°rbol.

**Ventajas y *Desventajas**

Los √°rboles de decisi√≥n ofrecen interpretabilidad y son computacionalmente eficientes, pero pueden ser sensibles a la muestra de datos y propensos al sobreajuste.

üìö Para una comprensi√≥n m√°s profunda, consulta este documento sobre el concepto de "mejor separaci√≥n" https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf.

**Preparando el Entorno**

Utilizaremos los siguientes paquetes:

tidyverse: Para el procesamiento de datos.
rpart: Implementaci√≥n de √°rboles de clasificaci√≥n.
rpart.plot: Para visualizar resultados.
caret: Utilidades para clasificaci√≥n y regresi√≥n, incluyendo matrices de confusi√≥n.


```{r, message=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(caret)
```

Lo que sigue es conseguir nuestros datos.

# Importando nuestros datos
Descargaremos el conjunto de datos de vino, disponible en el Machine Learning Repository.

* https://archive.ics.uci.edu/ml/datasets/Wine

Necesitamos descargar dos archivos. El primero contiene los datos que usaremos, y el segundo contiene su descripci√≥n (metadatos), la cual nos ser√° de gran utilidad m√°s adelante.

```{r, eval=FALSE}
# Datos
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data", "wine.data")

# Informaci√≥n
download.file("https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names", "wine.names")
```

Como habr√°s notado, nuestros datos tienen una extensi√≥n de archivo no convencional: **.data**. En **R** no existe una funci√≥n espec√≠fica para leer archivos con esta extensi√≥n, similar a `red.csv()` o `read.dat()`, las cuales nos facilitan tarea de importar archivos de formatos espec√≠ficos. Lo mismmo pasa con el archivo con su descripci√≥n, que tiene la extensi√≥n **.name**.

Necesitamos explorar estos archivos para saber c√≥mo podemos leerlos. Para estos casos, usamos la funci√≥n `readLines()`, que lee archivos, l√≠nea por l√≠nea, independientemente de su extensi√≥n o formato. con el argumento `n = 10` indicamos que s√≥lo deseamos leer las primeras diez l√≠neas de cada archivo.

Empezamos con los datos.
```{r}
readLines("wine.data", n = 10)
```

El archivo de datos parece ser una tabla de datos rectangular, con columnas separadas por comas. Entonces leer este archivo es f√°cil. El √∫nico inconveniente que tenemos es que nos faltan los nombres de cada columna.

Podemos usar `read_table()` para leer este archivo. Esta funci√≥n est√° dise√±ada para leer tablas de datos, es decir, con estructura rectangular (renglones y columnas).

Para asegurarnos que los datos ser√°n le√≠dos de manera correcta, especificamos que el separador de las columnas es una coma (`sep = ","`) y que no tenemos nombres de columna en nuestro archivo (`header = FALSE`). Asignamos el resultado al objeto **vino**.
```{r}
vino <- read.table("wine.data", sep = ",", header = FALSE)
```

Veamos los datos.
```{r}
vino
```

Tenemos 178 renglones y 14 columnas. Aunque a√∫n no sabemos que contienen.

Veamos si el archivo **wine.names** tiene respuestas.
```{r}
readLines("wine.names", n = 10)
```

Parece ser un archivo de texto com√∫n y corriente, pero con una extensi√≥n inusual. Podemos crear una copia de este archivo con la extensi√≥n a **.txt** con `file.copy()` para leerlo f√°cilmente en bloc de notas o cualquier aplicaci√≥n similar. Despu√©s, usamos `file.show()` para darle una lectura.
```{r, eval=FALSE}
file.copy(from = "wine.names", to = "wine_names.txt")

file.show("wine_names.txt")
```

A partir de lo que este documento explica, descubrimos que nuestros datos corresponden a trece caracter√≠sticas qu√≠micas de tres tipos de vinos. Esto quiere decir que una de las columnas de nuestros datos indica el tipo de vino y las otras trece son sus caracter√≠sticas.

Aunque es probable que la primera columna de nuestros datos sea la variable con el tipo de vino, usamos `summary()` para asegurarnos
```{r}
summary(vino)
```

Como la **V1** es la √∫nica con un valor m√≠nimo de 1 y m√°ximo de 3, es seguro que corresponde al tipo de vino, as√≠ que podemos renombrarla para facilitar el an√°lisis.

El resto de nombres de columna los podemos obtener del archivo con la informaci√≥n de los datos, haciendo algo de manipulaci√≥n con expresiones regulares (regex), a trav√©s de `gsub()`.

```{r}
# Leemos las l√≠neas del archivo "wine_names.txt" y seleccionamos las l√≠neas del 58 al 70
nombres <- readLines("wine_names.txt")[58:70] %>% 
  # Utilizamos gsub para eliminar cualquier car√°cter de control y lo que sigue hasta ")"
  gsub("[[:cntrl:]].*\\)", "", .) %>% 
  # Eliminamos espacios en blanco al principio y al final de cada nombre
  trimws() %>% 
  # Convertimos todos los caracteres a min√∫sculas
  tolower() %>% 
  # Reemplazamos espacios y "/" con "_"
  gsub(" |/", "_", .) %>% 
  # Agregamos el nombre "tipo" como primera columna para los tipos de vino
  c("tipo", .)

```

Ahora podemos cambiar los nombres de nuestros datos.
```{r}
names(vino) <- nombres 
vino
```

Por √∫ltimo, cambiamos el tipo de dato de la columna **tipo** a **factor** usando la funci√≥n `mutate_at()` de *dplyr*, para poder hacer clasificaciones. De otro modo, como esta columna tiene valores num√©ricos, podemos tener conflictos m√°s adelante. 
```{r}
vino <- vino %>% 
  mutate_at("tipo", factor)
vino
```

Ahora s√≠, empecemos a crear √°rboles de clasificaci√≥n.

# Creando un sets de entrenamiento y prueba
Necesitamos un set de entrenamiento para generar un modelo predictivo, y un set de prueba, para comprobar la eficacia de este modelo para hacer predicciones correctas.

Usamos la funci√≥n `sample_frac()` de *dplyr* para obtener un subconjunto de nuestros datos, que consiste en 70% del total de ellos. Usamos tambi√©n `set.seed()` para que este ejemplo sea reproducible.
```{r}
set.seed(1649)
vino_entrenamiento <- sample_frac(vino, .7)
```

Con `setdiff()` de *dplyr*, obtenemos el subconjunto de datos complementario al de entrenamiento para nuestro set de prueba, esto es, el 30% restante.
```{r}
vino_prueba <- setdiff(vino, vino_entrenamiento)
```



# Entrenando nuestro modelo
Usamos la funci√≥n `rpart` de *rpart* para entrenar nuestro modelo. Esta funci√≥n nos pide una formula para especificar la variable objetivo de la clasificaci√≥n. La formula que usaremos es `tipo ~ .`, la cual expresa que intentaremos clasificar **tipo** usando a todas las dem√°s variables como predictoras.

En este primer intento no ajustaremos ning√∫n otro par√°metro.
```{r}
arbol_1 <- rpart(formula = tipo ~ ., data = vino_entrenamiento)
```

Es hora de ver c√≥mo nos ha ido con nuestro modelo

# Evaluando nuestro modelo
Del entrenamiento de nuestro modelo obtenemos el siguiente resultado.
```{r}
arbol_1
```

*root 125 75 2 (0.352 0.400 0.248)*

*Hay 125 observaciones totales en el nodo ra√≠z.*

75 se clasificar√≠an mal si asignamos a todo el nodo la clase predicha.

La clase predicha (yval) es 2 (la segunda clase).

En el nodo, la proporci√≥n de clases es (35.2% de la 1, 40% de la 2, 24.8% de la 3).

proline >= 755 48 6 1 (0.875 0.042 0.083) # recorda que 755 es el punto de corte

De las 125 observaciones, 48 cumplen proline >= 755.

Si asignamos a todo ese subnodo la clase 1, cometer√≠amos 6 errores.

La clase predicha es 1 y sus proporciones internas son 87.5% (clase 1), 4.2% (clase 2), 8.3% (clase 3).

flavanoids >= 2.35 41 1 1 (0.976 0.024 0.000)

Dentro del subnodo de proline >= 755, 41 cumplen flavanoids >= 2.35.

Si asignamos a todo ese subnodo la clase 1, hay solo 1 error.

La clase predicha es 1 con 97.6% de observaciones de clase 1.

El asterisco (*) indica que es un nodo terminal (no se divide m√°s).

flavanoids < 2.35 7 3 3 (0.286 0.143 0.571)

En el subnodo hermano, hay 7 observaciones (a√∫n con proline >= 755 pero flavanoids < 2.35).

Se equivocar√≠a en 3 si se rotula con la clase 3.

La clase predicha es 3, con proporciones 28.6% (clase 1), 14.3% (clase 2), 57.1% (clase 3).

Tambi√©n es un nodo terminal.

proline < 755 77 29 2 (0.026 0.623 0.351)

El otro gran subnodo del nodo ra√≠z contiene 77 observaciones con proline < 755.

Se equivocar√≠an 29 si se rotula todo como clase 2.

Predice clase 2, con proporciones 2.6% (clase 1), 62.3% (clase 2), 35.1% (clase 3).

flavanoids >= 1.265 51 4 2 (0.039 0.922 0.039)

Dentro de proline < 755, hay 51 casos con flavanoids >= 1.265.

Cometer√≠a 4 errores si todo se cataloga como clase 2.

Predice clase 2, con distribuci√≥n 3.9% (clase 1), 92.2% (clase 2), 3.9% (clase 3).

Nodo terminal.

flavanoids < 1.265 26 1 3 (0.000 0.038 0.962)

Por √∫ltimo, 26 observaciones cumplen proline < 755 y flavanoids < 1.265.

Se equivocar√≠a en 1 si se rotula como clase 3.

Predice clase 3, con un 96.2% perteneciente a la clase 3.

Nodo terminal.

En resumen, el √°rbol divide primero seg√∫n la variable proline y, dentro de cada rama, ajusta el corte con flavanoids. Cada nodo terminal muestra cu√°ntas observaciones terminan all√≠, cu√°ntas se equivocar√≠an si se etiquetan con la clase mayoritaria de ese nodo y cu√°l es la distribuci√≥n de las clases en ese nodo.


```{r}
rpart.plot(arbol_1)
```

En estos gr√°ficos, cada uno de los rect√°ngulos representa un **nodo** de nuestro √°rbol, con su regla de clasificaci√≥n. 

Cada nodo est√° coloreado de acuerdo a la categor√≠a mayoritaria entre los datos que agrupa. Esta es la categor√≠a que ha predicho el modelo para ese grupo.

Dentro del rect√°ngulo de cada nodo se nos muestra qu√© proporci√≥n de casos pertenecen a cada categor√≠a y la proporci√≥n del total de datos que han sido agrupados all√≠. Por ejemplo, el rect√°ngulo en el extremo inferior izquierdo de la gr√°fica tiene 94% de casos en el tipo 1, 2% el tipos 2 y 0% en el tipo 3, que representan 33% de todos los datos.

Estas proporciones nos dan una idea de la precisi√≥n de nuestro modelo al hacer predicciones. De este modo, las reglas que conducen al rect√°ngulo que acabamos de mencionar nos dan un 94% de clasificaciones correctas. 


Pero, por supuesto, necesitamos ser m√°s sistem√°ticos para indagar qu√© tan bien hace predicciones nuestro modelo.

Usamos la funci√≥n `precict()` con nuestro set de prueba para generar un vector con los valores predichos por el modelo que hemos entrenado, especificamos el par√°metro `type = "class"`.

argumento `type = "class` para 
```{r}
prediccion_1 <- predict(arbol_1, newdata = vino_prueba, type = "class")
```

Cruzamos la predicci√≥n con los datos reales de nuestro set de prueba para generar una matriz de confusi√≥n, usando `confusionMatrix()` de *caret*.
```{r}
confusionMatrix(prediccion_1, vino_prueba[["tipo"]])
```
atento McNemar's Test P-Value = NA aparece porque esta prueba no aplica para clasificaci√≥n con m√°s de 2 clases. No es un error, es una limitaci√≥n l√≥gica del test.





**Vamos a trabajar con un conjunto de datos de una cartera de clientes de un banco.**

Los datos est√°n relacionados con campa√±as de marketing directo de una instituci√≥n bancaria portuguesa. Las campa√±as de marketing se basaron en llamadas telef√≥nicas. A menudo, se requer√≠a m√°s de un contacto con el mismo cliente, para poder conocer si el producto estar√≠a suscrito. El objetivo de la clasificaci√≥n es predecir si un cliente, con un perfil determinado, suscribir√° un dep√≥sito a plazo fijo.

```{r}
#install.packages("liver")
library(liver)
data("bank")
bank
```


# Distribuci√≥n de la variable objetivo

Queremos saber cuantos casos hay en el conjunto de datos con clientes que fueron contactados y suscribieron a un dep√≥sito.

```{r}
prop.table(table(bank$deposit))
```

# Particionar el conjunto de datos

Debemos dividir al conjunto de datos en dos. Con una parte (training) vamos a entrenar el modelo y obtener ciertos patrones que definen a los clientes con m√°s chances de suscribir. La otra parte (testing) vamos a utilizarla para validar la veracidad de estos patrones o si estos son producto del azar o la casualidad.

Vamos a seleccionar un 70% para entrenar y un 30% para testear.

```{r}
seleccionTest <- runif(n=nrow(bank))

bank_test <- bank[seleccionTest >.7 ,    ]
bank_tr <- bank[seleccionTest <= .7 ,    ] #Conjunto de entrenamiento sin balancear
```

Observamos como quedaron distribuidas las variables objetivos en el training y testing.

```{r}
#prop.table(table(bank_tr$deposit))
prop.table(table(bank_test$deposit))
table(bank_tr$deposit)
```


```{r}
#install.packages("rpart")
library(rpart)
f <- "deposit ~ age + job + marital +
education + default + balance + housing + loan +
contact + day + month"

```


```{r}
#library(rpart)
t <- rpart(formula = deposit~., method = "class", data = bank_tr)
```

### Visualizamos el √°rbol / investigar como guardar el arbol - investigar graficos interactivos de arboles!!

```{r}
#install.packages("rpart.plot")
library(rpart.plot)

# Gr√°fico del √°rbol
rpart.plot(t)

```

```{r}
predArbol1_tr <- predict (t, newdata = bank_tr, type="prob")
predArbol1_test <- predict (t, newdata = bank_test, type="prob")
```

### Matrices de confusi√≥n

`
```{r}

# Paso 1: Clasificaci√≥n binaria con umbral 0.5
pred_clasif <- ifelse(predArbol1_tr[, "yes"] > 0.5, "yes", "no")

# Paso 2: Convertir a factores con los mismos niveles que la variable real
pred_clasif <- factor(pred_clasif, levels = c("no", "yes"))
real <- factor(bank_tr$deposit, levels = c("no", "yes"))

# Paso 3: Matriz de confusi√≥n y m√©tricas
confusion <- confusionMatrix(pred_clasif, real, positive = "yes")

# Mostrar todo el resumen
print(confusion)

```


Los t√≠picos par√°metros para manipular un √°rbol son:

-   minsplit : m√≠nimo numero de observaciones par dividir un nodo
-   maxdepth : es la profundidad m√°xima del nodo
-   minbucket : m√≠nimo numero de observaciones de un nodo

"cp" en RStudio se utiliza para controlar la complejidad del √°rbol de decisi√≥n mediante la poda, lo que ayuda a evitar el sobreajuste y mejorar la capacidad predictiva del modelo.

### Definimos nuevos par√°metros / ESTO POR FAVOR MIRAR EN AUTONOMIA!!!

```{r}
controles <- rpart.control(minsplit = 20, minbucket = 20, 
                           cp =0.001, maxcompete = 4, 
                           maxsurrogate = 5,
                           usesurrogate = 2, 
                           xval = 10,surrogatestyle = 0,
                           maxdepth = 8)

```


```{r}
#Quiero un √°rbol m√°s frondoso
#probar eliminar la variable month
t <- rpart(formula = deposit~.-month, method = "class", 
           data = bank_tr, control = controles)
```

#Les menciono metodo class porque los arboles pueden reconocer pero si usamos regresi√≥n es bueno decirle que es para una regresi√≥n


```{r}
# viasulaziation
library(rpart.plot)

# Abrir dispositivo PDF
pdf("arbol_decision.pdf")

# Gr√°fico del √°rbol
rpart.plot(t)

# Cerrar dispositivo PDF
dev.off()
```

```{r}
predArbol1_tr <- predict (t, newdata = bank_tr, type="prob")
predArbol1_test <- predict (t, newdata = bank_test, type="prob")
```




```{r}
# Clasificaci√≥n binaria desde probabilidades con umbral 0.5
pred_clasif <- ifelse(predArbol1_tr[, "yes"] > 0.5, "yes", "no")

# Convertir en factor con niveles consistentes
pred_clasif <- factor(pred_clasif, levels = c("no", "yes"))
real <- factor(bank_tr$deposit, levels = c("no", "yes"))

# Matriz de confusi√≥n y m√©tricas completas
confusion <- confusionMatrix(pred_clasif, real, positive = "yes")

# Mostrar todo
print(confusion)

```


# Valuaci√≥n del modelo

-   Costos Variables: 1000 AR\$ x contacto
-   Ingresos: 2000 AR\$ x venta


```{r}
umbral<-0.5
TP <- sum(predArbol1_test[, "yes"] > umbral & bank_test$deposit == "yes")
FP <- sum(predArbol1_test[, "yes"] > umbral & bank_test$deposit == "no")
FN <- sum(predArbol1_test[, "yes"] < umbral & bank_test$deposit == "yes")
TN <- sum(predArbol1_test[, "yes"] < umbral & bank_test$deposit == "no")

# O bien usando confusion$table:
# confusion$table
# #     Reference
# # Pred   no yes
# #   no   TN FN
# #   yes  FP TP
#
# Ej. TP <- confusion$table["yes","yes"]

```


```{r}
costo_contacto <- 100
ingreso_venta  <- 3000

contactos_realizados <- TP + FP  # Todos los casos predichos como "yes"
Resultado <- ingreso_venta * TP - costo_contacto * contactos_realizados

cat("Ganancia total = $", Resultado, "\n",
    "Contactos realizados =", contactos_realizados, "\n",
    "TP (Ventas efectivas) =", TP, "\n")

```




**Ahora primer desafio Balancear los yes para sean igual a los no, como daria el resultado de la campa√±a?** (/ )


Segundo ejercicio
# El objetivo de este an√°lisis es predecir la especie de ping√ºino mediante arboles
# (Adelie, Chinstrap o Gentoo) bas√°ndose en otras variables 
# (como longitud del pico, longitud de la aleta, isla, sexo, etc.). ( )


# üåü Interpretaci√≥n del C√≥digo:

- **`predArbol1_test[,2]`**:
  - üìä `predArbol1_test` es una matriz de probabilidades generada por el modelo de √°rbol de decisi√≥n (`rpart`) para los datos de prueba (`bank_test`).
  - üî¢ El uso de `[ ,2]` selecciona todas las filas (`[ , ]`) de la **segunda columna** de esta matriz. La segunda columna representa la probabilidad de que la clase sea "yes" (que el cliente acepte el dep√≥sito) en tu modelo de clasificaci√≥n binaria.
  - üëâ Por lo tanto, `predArbol1_test[,2]` contiene todas las probabilidades de que cada cliente en el conjunto de prueba acepte el dep√≥sito.

- **C√°lculos de TP, FP, FN, TN**:
  - üìà Estos c√°lculos determinan los diferentes conteos necesarios para crear una matriz de confusi√≥n y evaluar el rendimiento del modelo.

  - **TP (True Positives o Verdaderos Positivos):**  
    ```r
    TP <- sum(predArbol1_test[,2] > umbral & bank_test$deposit == "yes")
    ```
    ‚úîÔ∏è Aqu√≠, `predArbol1_test[,2] > umbral` crea un vector l√≥gico (TRUE o FALSE) indicando si la probabilidad predicha de la clase "yes" es mayor que el umbral especificado (0.5, en este caso).  
    ‚ûï Al combinarlo con `bank_test$deposit == "yes"`, solo se cuenta como `TRUE` si ambos son verdaderos, es decir, si el modelo predice "yes" con una probabilidad mayor que el umbral **y** el valor real de `deposit` es "yes". La funci√≥n `sum()` luego cuenta cu√°ntos de estos casos son verdaderos, proporcionando el n√∫mero de verdaderos positivos.

  - **FP (False Positives o Falsos Positivos):**  
    ```r
    FP <- sum(predArbol1_test[,2] > umbral & bank_test$deposit == "no")
    ```
    ‚ùå Similar a `TP`, pero en este caso, se cuenta si la probabilidad predicha es mayor que el umbral (el modelo predice "yes") **pero** el valor real es "no". Esto proporciona el n√∫mero de falsos positivos.

  - **FN (False Negatives o Falsos Negativos):**  
    ```r
    FN <- sum(predArbol1_test[,2] < umbral & bank_test$deposit == "yes")
    ```
    üö´ Este c√°lculo cuenta los casos donde el modelo predice "no" (probabilidad menor que el umbral) **pero** el valor real es "yes", proporcionando el n√∫mero de falsos negativos.

  - **TN (True Negatives o Verdaderos Negativos):**  
    ```r
    TN <- sum(predArbol1_test[,2] < umbral & bank_test$deposit == "no")
    ```
    ‚úÖ Finalmente, este c√°lculo cuenta los casos donde el modelo predice "no" (probabilidad menor que el umbral) **y** el valor real es "no", proporcionando el n√∫mero de verdaderos negativos.

# üîç **En Resumen**:
- El uso de `[,2]` en `predArbol1_test[,2]` selecciona la segunda columna de la matriz de probabilidades de predicci√≥n, que corresponde a la probabilidad de la clase "yes". 
- üìä Los c√°lculos de TP, FP, FN, y TN dependen de comparar estas probabilidades con un umbral para clasificar las predicciones como verdaderas o falsas en relaci√≥n con los valores reales de la variable objetivo (`deposit`).


üîÑ¬øQu√© significa ‚Äúbalancear‚Äù las clases?
Cuando una clase es mucho m√°s frecuente que la otra, el modelo tiende a enfocarse en la mayor√≠a y ‚Äúolvida‚Äù la clase minoritaria, incluso si esa es la m√°s importante para el negocio (por ejemplo, los clientes que dicen "s√≠" a una oferta).

üí° Balancear significa:

Modificar el conjunto de entrenamiento (no el real) para que el modelo aprenda mejor a reconocer ambas clases.

Esto se hace con t√©cnicas como:

Upsampling: duplicar ejemplos de la clase minoritaria.

Downsampling: reducir ejemplos de la clase mayoritaria.

‚ö†Ô∏è NO se cambia el conjunto de prueba ni la realidad del negocio. Solo se entrena mejor.

üéØ ¬øEntonces es v√°lido?
S√≠, totalmente v√°lido y com√∫n en machine learning, siempre que:

üìä No se altere el conjunto de prueba (que vos no lo hiciste).

üß† Se entienda que el balance es una t√©cnica para mejorar el aprendizaje, no para ‚Äúenga√±ar‚Äù al modelo.

üíº Se interprete como una estrategia para proponer mejoras reales en campa√±as futuras.

üíº ¬øY c√≥mo se comunica al cliente o stakeholder?

es perfecto para una recomendaci√≥n estrat√©gica basada en simulaci√≥n:

"Si logramos identificar y priorizar mejor a los clientes tipo 's√≠', por ejemplo ajustando la estrategia de contacto o dise√±ando campa√±as m√°s dirigidas, el modelo muestra que podr√≠amos aumentar las ventas hasta $285.900 en vez de $147.700."

O bien:

"Mediante t√©cnicas de balanceo, entrenamos al modelo para prestar m√°s atenci√≥n a los clientes que suelen decir que s√≠. Esto mejora el recall y da una predicci√≥n m√°s √∫til si el objetivo es maximizar ingresos."
