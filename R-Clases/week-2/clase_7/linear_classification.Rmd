# Proyecto de ML en R: Regresión logística 

- [Fuente de datos:](https://raw.githubusercontent.com/niaj-a/Machine-Learning/refs/heads/master/10.classification-metrics/heart.csv)

## Objetivo: Clasificar si un paciente tiene enfermedad cardiaca (target: target)

# Requisitos: instalar los paquetes necesarios si no están instalados
```{R instalar-packages-necesarios}
required_pkgs <- c('tidyverse', 'tidymodels', 'GGally', 'corrplot', 'vip', 'ranger', 'xgboost', 'glmnet')
new_pkgs <- required_pkgs[!(required_pkgs %in% installed.packages()[, 'Package'])]
if(length(new_pkgs)) install.packages(new_pkgs)
```

```{R importacion-librerias}
library(tidyverse)
library(tidymodels)
library(GGally) # es como una dependecias simil a ggplot
library(corrplot)
library(vip) # variable importance plot

set.seed(123)
```


### Cargar datos
```{R data-loading}
url <- 'https://raw.githubusercontent.com/niaj-a/Machine-Learning/refs/heads/master/10.classification-metrics/heart.csv'
heart <- read_csv(url)

# Resumen rápido
glimpse(heart)
summary(heart)
```

###  EDA
  *Conteo de la variable objetivo*
```{R eda-historico-analitico}

heart %>% 
  count(target) %>% 
  mutate(freq = n / sum(n))

#  - Distribuciones de algunas variables contínuas
heart %>% 
  select(age, trestbps, chol, thalach) %>% gather() %>%
  ggplot(aes(value)) +
  geom_histogram(bins = 30) +
  facet_wrap(~key, scales = 'free') +
  labs(title = 'Distribuciones: age, trestbps, chol, thalach')

#  - Boxplots por target
heart %>% 
  # no recuerdo sobre el pivote se pueda usar, pero hay una alternativa sin dependencias
  # gather(key = "feature", value = "value", age, trestbps, chol, thalach)
  pivot_longer(cols = c(age, trestbps, chol, thalach), names_to = 'feature') %>%
  ggplot(aes(x = factor(target), y = value)) + geom_boxplot() + facet_wrap(~feature, scales = 'free') +
  labs(x = 'target', title = 'Boxplots por target')
```

### 3) Hipótesis nula (ejemplos):
```{R planteo-hipotesis}
#  H0: No hay asociación entre el tipo de dolor en el pecho (cp) y la presencia de enfermedad cardiaca (target).
#  H1: Existe asociación entre cp y target.
# Se puede probar con test chi-cuadrado sobre la tabla cp vs target.
chisq_test_cp <- heart %>% 
  select(cp, target) %>% 
  table() %>% 
  chisq.test()

chisq_test_cp
```



# 4) Correlaciones y mapa de calor (solo variables numéricas)
num_vars <- heart %>% select_if(is.numeric)
cor_mat <- cor(num_vars)

# Mostrar mapa de calor con corrplot
corrplot::corrplot(cor_mat, method = 'color', tl.cex = 0.8, number.cex = 0.7)

# O con GGally (pairs corr)
# GGally::ggpairs(num_vars)

# 5) Detectar y completar NA (si hay)
sum(is.na(heart))
# Si hubiera NA, podemos imputar; en este dataset hay pocos o ninguno.

# 6) Tratamiento de outliers
# Ejemplo simple: winsorize por percentiles 1% y 99% para variables numéricas
winsorize <- function(x, p = 0.01){
  if(is.numeric(x)){
    qnts <- quantile(x, probs = c(p, 1 - p), na.rm = TRUE)
    x[x < qnts[1]] <- qnts[1]
    x[x > qnts[2]] <- qnts[2]
  }
  x
}
heart_w <- heart %>% mutate(across(where(is.numeric), ~ winsorize(.x, 0.01)))

# 7) Feature engineering
#  - Convertir variables categóricas que vienen como numéricas
# Revisar nombres y tipos
str(heart_w)

# Según dataset: cp, restecg, slope, ca, thal pueden ser factores
heart_w <- heart_w %>%
  mutate(across(c(cp, restecg, slope, ca, thal, sex, fbs, exang), ~ as.factor(.x)))

#  - Crear variables derivadas si tiene sentido (ejemplo: edad_bin)
heart_w <- heart_w %>% mutate(age_bin = case_when(
  age < 40 ~ 'young',
  age < 60 ~ 'mid',
  TRUE ~ 'old'
) %>% factor(levels = c('young', 'mid', 'old')))

# 8) Split: train (60%), validation (20%), test (20%)
set.seed(123)
initial_split <- initial_split(heart_w, prop = 0.8, strata = target) # train + val (80%) vs test (20%)
train_val <- training(initial_split)
test_set <- testing(initial_split)

# Ahora dividir train_val en train (75% of 80% = 60%) y validation (25% of 80% = 20%)
set.seed(123)
split_tv <- initial_split(train_val, prop = 0.75, strata = target)
train_set <- training(split_tv)
validation_set <- testing(split_tv)

dim(train_set); dim(validation_set); dim(test_set)

# 9) Preparar receta (preprocesamiento común)
#   - One-hot encoding para factores, centrar/escalar numeric, imputación si necesario, remover zero var
rec <- recipe(target ~ ., data = train_set) %>%
  update_role(patient_id, new_role = "ID") %>% # si existe patient_id, eliminar rol (ejemplo)
  step_mutate(target = as.factor(target)) %>%
  step_unknown(all_nominal(), -all_outcomes()) %>% # por si hay NA en factores
  step_impute_median(all_numeric(), -all_outcomes()) %>%
  step_impute_mode(all_nominal(), -all_outcomes()) %>%
  step_other(all_nominal(), -all_outcomes(), threshold = 0.01) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_zv(all_predictors())

# Preparar la receta con el conjunto de entrenamiento
rec_prep <- rec %>% prep(training = train_set)
train_baked <- bake(rec_prep, new_data = train_set)
validation_baked <- bake(rec_prep, new_data = validation_set)
test_baked <- bake(rec_prep, new_data = test_set)

# 10) Modelos a comparar (al menos 3):
#   - Regresión logística (baseline)
#   - Regresión logística regularizada (glmnet)
#   - Random Forest (ranger)
#   - XGBoost (opcional)

# 10.1) Logistic regression (glm)
log_spec <- logistic_reg(mode = 'classification', penalty = 0, mixture = 0) %>%
  set_engine('glm')

log_wf <- workflow() %>% add_model(log_spec) %>% add_recipe(rec)

# 10.2) Regularized logistic (glmnet) -- tune penalty
glmnet_spec <- logistic_reg(mode = 'classification', penalty = tune(), mixture = 1) %>%
  set_engine('glmnet')

glmnet_wf <- workflow() %>% add_model(glmnet_spec) %>% add_recipe(rec)

# 10.3) Random Forest (ranger)
rf_spec <- rand_forest(mtry = tune(), trees = 1000, min_n = tune()) %>%
  set_engine('ranger') %>%
  set_mode('classification')

rf_wf <- workflow() %>% add_model(rf_spec) %>% add_recipe(rec)

# 10.4) XGBoost (boost_tree)
xgb_spec <- boost_tree(trees = 1000, tree_depth = tune(), learn_rate = tune(), mtry = tune(), min_n = tune()) %>%
  set_engine('xgboost') %>% set_mode('classification')

xgb_wf <- workflow() %>% add_model(xgb_spec) %>% add_recipe(rec)

# 11) Resampling y búsqueda de hiperparámetros
set.seed(234)
folds <- vfold_cv(train_set, v = 5, strata = target)

# Grid para glmnet, rf y xgb
glmnet_grid <- grid_regular(penalty(range = c(-4, 0)), levels = 10) %>%
  mutate(penalty = 10^penalty) # convertir exponente a escala

rf_grid <- grid_regular(mtry(range = c(1, sqrt(ncol(train_baked) - 1))), min_n(range = c(2, 20)), levels = 5)

xgb_grid <- grid_latin_hypercube(tree_depth(range = c(1, 6)), learn_rate(range = c(-3, -1)), mtry(range = c(1, ncol(train_baked) - 1)), min_n(range = c(2, 20)), size = 10) %>%
  mutate(learn_rate = 10^learn_rate)

# Nota: ajustar grids dependiendo del número de predictores para evitar valores inválidos

# 11.1) Tuning glmnet
set.seed(345)
glmnet_res <- tune_grid(
  glmnet_wf,
  resamples = folds,
  grid = glmnet_grid,
  metrics = metric_set(roc_auc, accuracy, f_meas)
)

# 11.2) Tuning random forest (puede ser lento)
set.seed(345)
rf_res <- tune_grid(
  rf_wf,
  resamples = folds,
  grid = rf_grid,
  metrics = metric_set(roc_auc, accuracy, f_meas)
)

# 11.3) Tuning xgboost
set.seed(345)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = folds,
  grid = xgb_grid,
  metrics = metric_set(roc_auc, accuracy, f_meas)
)

# 12) Seleccionar mejores modelos según ROC AUC
best_glmnet <- select_best(glmnet_res, 'roc_auc')
best_rf <- select_best(rf_res, 'roc_auc')
best_xgb <- select_best(xgb_res, 'roc_auc')

# Finalizar workflows con mejores hiperparámetros
final_glmnet_wf <- finalize_workflow(glmnet_wf, best_glmnet)
final_rf_wf <- finalize_workflow(rf_wf, best_rf)
final_xgb_wf <- finalize_workflow(xgb_wf, best_xgb)

# 13) Ajustar en train_set completo y evaluar en validation_set
final_glmnet_fit <- final_glmnet_wf %>% fit(data = train_set)
final_rf_fit <- final_rf_wf %>% fit(data = train_set)
final_xgb_fit <- final_xgb_wf %>% fit(data = train_set)

# Predecir en validation
pred_glmnet <- predict(final_glmnet_fit, validation_set, type = 'prob') %>% bind_cols(predict(final_glmnet_fit, validation_set)) %>% bind_cols(validation_set %>% select(target))
pred_rf <- predict(final_rf_fit, validation_set, type = 'prob') %>% bind_cols(predict(final_rf_fit, validation_set)) %>% bind_cols(validation_set %>% select(target))
pred_xgb <- predict(final_xgb_fit, validation_set, type = 'prob') %>% bind_cols(predict(final_xgb_fit, validation_set)) %>% bind_cols(validation_set %>% select(target))

# 14) Calcular métricas en validation
metrics_set <- metric_set(roc_auc, accuracy, precision, recall, f_meas)

metrics_glmnet <- metrics_set(pred_glmnet, truth = target, estimate = .pred_class, .pred_1)
metrics_rf <- metrics_set(pred_rf, truth = target, estimate = .pred_class, .pred_1)
metrics_xgb <- metrics_set(pred_xgb, truth = target, estimate = .pred_class, .pred_1)

# 15) Comparar resultados
list(glmnet = metrics_glmnet, rf = metrics_rf, xgb = metrics_xgb)

# 16) Evaluación final en test_set con el mejor modelo (ejemplo: el de mayor roc_auc en validation)
# Suponiendo que best_model_name es 'rf' por ejemplo:
# best_final <- final_rf_fit
# pred_test <- predict(best_final, test_set, type = 'prob') %>% bind_cols(predict(best_final, test_set)) %>% bind_cols(test_set %>% select(target))
# metrics_test <- metrics_set(pred_test, truth = target, estimate = .pred_class, .pred_1)

# 17) Interpretabilidad: importancia de variables (vip)
# vip::vip(final_rf_fit$fit$fit) # depende de engine: para ranger trabajar con el objeto interno

# 18) Guardar modelo si se desea
# saveRDS(final_rf_fit, 'final_rf_fit.rds')

# 19) Reporte y conclusiones
# - Resumir la performance en train/validation/test
# - Confirmar o rechazar hipótesis nula según pruebas estadísticas y la importancia de features
# - Recomendaciones: recolección de más datos, calibración de probabilidades, análisis de subgroup

# Fin del script
