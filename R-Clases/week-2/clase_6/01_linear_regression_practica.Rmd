---
title: "Regresi√≥n Lineal y Modelos Regularizados con tidymodels"
author: "Anderson Oca√±a"
date: "`r Sys.Date()`"
output: 
  # html_document:
  #   toc: true
  #   toc_float: true
  #   theme: united
  #   highlight: tango
  #   code_folding: show
  pdf_document:
    toc: true
    number_sections: true
    highlight: tango
fontsize: 10pt
geometry: margin=1in
---


```{R install, include=FALSE}
packages <- c("tidymodels", "ggplot2", "dplyr","glmnet", "ranger", "xgboost")
install.packages(setdiff(packages, rownames(installed.packages())))
```

```{R setup, include=FALSE}
library(tidymodels)
library(ggplot2)
library(dplyr)
````

# 1. Introducci√≥n

En este documento trabajaremos con **regresi√≥n lineal** como modelo base y veremos variantes regularizadas (**Ridge** y **Lasso**) para mejorar la robustez y manejar multicolinealidad.
Usaremos el dataset integrado `mtcars`.

---

# 2. Carga y exploraci√≥n de datos

```{R}
data(mtcars)
glimpse(mtcars)
summary(mtcars)
```

### *renombre de variables*

```{R rename-dataset}
library(dplyr)

names_mtcars <- c(
  "miles_per_gallon",     # mpg
  "num_cylinders",        # cyl
  "displacement",         # disp
  "horsepower",          # hp
  "rear_axle_ratio",     # drat
  "weight",              # wt
  "quarter_mile_time",   # qsec
  "engine_type",         # vs (0 = V-shaped, 1 = straight)
  "transmission",        # am (0 = automatic, 1 = manual)
  "num_gears",          # gear
  "num_carburetors"     # carb
)

mtcars <- mtcars %>%initial_split
  `names<-`(names_mtcars)

summary(mtcars)
```


```{R nullish-validate}

null_counts <- mtcars %>%
  summarise_all(~ sum(is.na(.))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Null_Count")

print(null_counts)

p1 <- ggplot(
  data=null_counts,
  aes(x = reorder(Variable, -Null_Count), y = Null_Count)) +

  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
  geom_text(aes(label = Null_Count), vjust = -0.3, size = 3.5) +
  labs(
    title = "Cantidad de Valores Nulos por Variable",
    subtitle = "Dataset: mtcars",
    x = "Variables",
    y = "N√∫mero de Valores Nulos"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12)
  )

print(p1)

```

---

# 3. Definici√≥n de variables

La **variable objetivo** ser√° `mpg` (millas por gal√≥n): **miles_per_gallon**
La **variable predictora** inicial `wt` (peso del veh√≠culo en 1000 lbs): **weight**

---

# 4. EDA r√°pido

```{R}
mtcars %>%
  ggplot(aes(x = weight, y = miles_per_gallon)) +
  geom_point(color = "steelblue", size = 3) +
  geom_smooth(method = "lm", se = FALSE, color = "darkred") +
  labs(title = "Relaci√≥n entre peso y consumo de combustible",
       x = "Peso (1000 lbs)",
       y = "Millas por gal√≥n (mpg)")
```

---

# 5. Train/Test Split

```{R}
set.seed(42)
split <- initial_split(mtcars, prop = 0.8)
train_data <- training(split)
test_data  <- testing(split)

```

---

#### tidymodels 
- *[tidymodels oficial](https://www.tidymodels.org/)*
- *[tidymodels sample](https://diegokoz.github.io/EEA2019/clase%208/tidymodels.nb.html)*

- *rsample: for data splitting and resampling*
- *recipes: for data preprocessing and feature engineering*
- *parsnip: for model specification with unified syntax*
- *workflows: for combining preprocessing and models*
- *tune: for hyperparameter tuning*
- *yardstick: for model evaluation metrics*


# 6. Receta de preprocesamiento

Incluimos normalizaci√≥n de variables predictoras.

```{R}
car_recipe <- recipe(
  miles_per_gallon ~ ., data = train_data) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%  # Remueve variables con varianza cero
  step_corr(all_numeric_predictors(), threshold = 0.9)  # Remueve variables muy correlacionadas
```

---

# 7. Modelo base: Regresi√≥n Lineal

```{R}

lm_model <- linear_reg() %>%
  set_engine("lm") %>%
  set_mode("regression")


car_workflow <- workflow() %>%
  add_recipe(car_recipe) %>%
  add_model(lm_model)

```

---

# 8. Predicci√≥n y m√©tricas en test

```{R prediccion-metricas}

fitted_workflow <- fit(car_workflow, data=train_data)

print("predictions -> prediccion .pred del modelo")
linear_reg_predictions <- predict(fitted_workflow, new_data = test_data)

print("predictions -> predicciones intervalo de confianza .pred_upper, .pred_lower")
linear_reg_predictions_intervals <- predict(fitted_workflow, new_data = test_data, type = "conf_int")

print("merge de estas predicciones")
linear_reg_predictions <- bind_cols(test_data, linear_reg_predictions, linear_reg_predictions_intervals)

print("Nombre de las columnas de prediccion")
colnames(linear_reg_predictions)

print("Modelo entrenado:")
fitted_workflow

print("Predicciones:")
linear_reg_predictions
```

#### Metricas
```{R metricas}

metrics_tbl <- metrics(
  linear_reg_predictions,
  truth = miles_per_gallon,
  estimate = .pred
) %>%
  as_tibble()


# metrics <- as_tibble(metrics(linear_reg_predictions, truth = miles_per_gallon, estimate = .pred))

print(metrics)

# Calcular RMSE
test_rmse <- rmse(
  data = linear_reg_predictions,
  truth = miles_per_gallon,
  estimate = .pred
)

# Calcular MAE
test_mae <- mae(
  data = linear_reg_predictions,
  truth = miles_per_gallon,
  estimate = .pred
)

# Calcular R¬≤
test_rsq <- rsq(
  data = linear_reg_predictions,
  truth = miles_per_gallon,
  estimate = .pred
)

# Mostrar resultados
cat("Test RMSE:", round(test_rmse$.estimate, 4), "\n")
cat("Test MAE :", round(test_mae$.estimate, 4), "\n")
cat("Test R¬≤  :", round(test_rsq$.estimate, 4), "\n")
```


## 1. **RMSE** ‚Äî *Root Mean Squared Error* (Ra√≠z del Error Cuadr√°tico Medio)

**Qu√© mide:**

* El **promedio** del tama√±o de los errores, pero elevando al cuadrado las diferencias antes de promediarlas y luego sacando la ra√≠z.
* Penaliza m√°s fuerte los errores grandes (outliers).

**Interpretaci√≥n:**

* Cuanto **menor**, mejor (cero ser√≠a predicci√≥n perfecta).
* Est√° en **las mismas unidades** que la variable objetivo (`miles_per_gallon` en tu caso).

**Ejemplo:**
Si predices 20 y el valor real es 22 (error de 2), y otra vez predices 20 pero el real es 28 (error de 8), el segundo error influye mucho m√°s en el RMSE que el primero.

---

## üìè 2. **MAE** ‚Äî *Mean Absolute Error* (Error Medio Absoluto)

**Qu√© mide:**

* El promedio del valor **absoluto** de las diferencias entre predicciones y valores reales.
* Todos los errores pesan igual.

**Interpretaci√≥n:**

* Cuanto **menor**, mejor.
* Tambi√©n est√° en las mismas unidades de la variable objetivo.

**Ejemplo:**
Si tienes errores de 2 y 8, el MAE = (2 + 8) / 2 = 5, sin importar que el segundo error sea mucho mayor.

---

## üìà 3. **R¬≤** ‚Äî *Coeficiente de Determinaci√≥n*

**Qu√© mide:**

* La **proporci√≥n de la varianza** de la variable objetivo que el modelo es capaz de explicar.
* Valores van de:

  * **1.0** ‚Üí predicci√≥n perfecta
  * **0.0** ‚Üí el modelo no mejora nada respecto a predecir la media
  * Negativo ‚Üí el modelo es peor que usar la media como predicci√≥n

**Interpretaci√≥n:**

* Si R¬≤ = 0.76, significa que el modelo explica el **76% de la variabilidad** de la variable objetivo.

---

## Resumen r√°pido

| M√©trica | Rango  | Mejor valor | Penaliza m√°s errores grandes? | Unidades              |
| ------- | ------ | ----------- | ----------------------------- | --------------------- |
| RMSE    | 0 ‚Üí ‚àû  | 0           | ‚úÖ S√≠                          | Igual que la variable |
| MAE     | 0 ‚Üí ‚àû  | 0           | ‚ùå No                          | Igual que la variable |
| R¬≤      | -‚àû ‚Üí 1 | 1           | ‚ùå (es porcentual)             | No aplica             |

---

Regla pr√°ctica:

* **RMSE**: √ösalo cuando quieres ser m√°s sensible a errores grandes.
* **MAE**: √ösalo cuando quieres un promedio m√°s ‚Äújusto‚Äù que no castigue tanto outliers.
* **R¬≤**: √ösalo para explicar cu√°nta variabilidad est√°s capturando, no para medir el error absoluto.
---


```{R valores-reales-vs-prediccion}
library(ggplot2)

ggplot(linear_reg_predictions, aes(x = miles_per_gallon, y = .pred)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = 0.2, alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(
    title = "Valores Reales vs Predichos con Intervalos de Confianza",
    subtitle = paste0(
      "RMSE: ", round(test_rmse$.estimate, 2),
      " | MAE: ", round(test_mae$.estimate, 2),
      " | R¬≤: ", round(test_rsq$.estimate, 2)
    ),
    x = "Valor Real (miles_per_gallon)",
    y = "Valor Predicho"
  ) +
  theme_minimal()
```


--- 
## Agregar algunos otros modelos para encontrar un mejor modelo adaptable

```{R}

# Modelo 1: Regresi√≥n Lineal
lm_model <- linear_reg() %>% set_engine("lm") %>% set_mode("regression")

ridge_model <- linear_reg(penalty = tune(), mixture = 0) %>% set_engine("glmnet")
lasso_model <- linear_reg(penalty = tune(), mixture = 1) %>% set_engine("glmnet")

# Modelo 2: Random Forest (sin tuning por ahora)
rf_model <- rand_forest(trees = 500) %>% set_engine("ranger") %>% set_mode("regression")

# Modelo 3: XGBoost (sin tuning por ahora)
xgb_model <- boost_tree(trees = 500) %>% set_engine("xgboost") %>% set_mode("regression")


workflows <- list(
  lm = workflow() %>% add_recipe(car_recipe) %>% add_model(lm_model),
  ridge = workflow() %>% add_recipe(car_recipe) %>% add_model(ridge_model),
  lasso = workflow() %>% add_recipe(car_recipe) %>% add_model(lasso_model),
  rf = workflow() %>% add_recipe(car_recipe) %>% add_model(rf_model),
  xgb = workflow() %>% add_recipe(car_recipe) %>% add_model(xgb_model)
)

```

```{R}
set.seed(42)

# Validaci√≥n cruzada
cv_splits <- vfold_cv(
    train_data
  , v = 5)
  # , strata = miles_per_gallon)

# Grid para tuning (solo para penalty)
penalty_grid <- grid_regular(penalty(range = c(-5, 0)), levels = 20) # log10 scale

# Tunear ridge
ridge_tune_results <- tune_grid(
  workflows$ridge,
  resamples = cv_splits,
  grid = penalty_grid,
  metrics = metric_set(rmse, mae, rsq)
)

# Tunear lasso
lasso_tune_results <- tune_grid(
  workflows$lasso,
  resamples = cv_splits,
  grid = penalty_grid,
  metrics = metric_set(rmse, mae, rsq)
)

# Seleccionar mejores par√°metros (basado en rmse)
best_ridge <- select_best(ridge_tune_results, metric ="rmse")
best_lasso <- select_best(lasso_tune_results, metric ="rmse")

# Finalizar workflows con mejores par√°metros
final_ridge <- finalize_workflow(workflows$ridge, best_ridge)
final_lasso <- finalize_workflow(workflows$lasso, best_lasso)

# Ajustar modelos finales con tuning
ridge_fit <- fit(final_ridge, data = train_data)
lasso_fit <- fit(final_lasso, data = train_data)

# Ajustar modelos sin tuning directo
lm_fit <- fit(workflows$lm, data = train_data)
rf_fit <- fit(workflows$rf, data = train_data)
xgb_fit <- fit(workflows$xgb, data = train_data)

# Funci√≥n para evaluar en test set
evaluate_model <- function(fitted_wf, test_data) {
  preds <- predict(fitted_wf, test_data) %>%
    bind_cols(test_data)
  metrics(preds, truth = miles_per_gallon, estimate = .pred)
}

# Evaluar todos
lm_metrics <- evaluate_model(lm_fit, test_data) %>% mutate(model = "Linear Regression")
ridge_metrics <- evaluate_model(ridge_fit, test_data) %>% mutate(model = "Ridge Regression")
lasso_metrics <- evaluate_model(lasso_fit, test_data) %>% mutate(model = "Lasso Regression")
rf_metrics <- evaluate_model(rf_fit, test_data) %>% mutate(model = "Random Forest")
xgb_metrics <- evaluate_model(xgb_fit, test_data) %>% mutate(model = "XGBoost")

# Combinar m√©tricas
all_metrics <- bind_rows(lm_metrics, ridge_metrics, lasso_metrics, rf_metrics, xgb_metrics)


cat("Mejor modelo seg√∫n RMSE:\n")

all_metrics_wide <- all_metrics %>%
  select(model, .metric, .estimate) %>%
  pivot_wider(
    names_from = .metric,
    values_from = .estimate
  ) %>%
  arrange(desc(rsq))

print(all_metrics_wide)
```




# Diagn√≥stico de residuos del modelo lineal

```{R}
library(tidymodels)
library(ggplot2)
library(gridExtra)  # Para mostrar m√∫ltiples gr√°ficos juntos


best_model_name <- all_metrics_wide %>%
  slice(1) %>%
  pull(model)


fits_list <- list(
  "Linear Regression" = lm_fit,
  "Ridge Regression" = ridge_fit,
  "Lasso Regression" = lasso_fit,
  "Random Forest" = rf_fit,
  "XGBoost" = xgb_fit
)

best_fit <- fits_list[[best_model_name]]

library(ggplot2)
library(gridExtra)

predictions <- predict(best_fit, test_data) %>%
  bind_cols(test_data) %>%
  mutate(
    residuals = miles_per_gallon - .pred,
    fitted = .pred,
    abs_residuals = abs(residuals),
    sqrt_abs_residuals = sqrt(abs_residuals)
  )

p1 <- ggplot(predictions, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = paste("Residuales vs Ajustados -", best_model_name),
       x = "Valores Ajustados (.pred)",
       y = "Residuales") +
  theme_minimal()

p2 <- ggplot(predictions, aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(title = paste("QQ-Plot de Residuales -", best_model_name)) +
  theme_minimal()

p3 <- ggplot(predictions, aes(x = residuals)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = paste("Histograma de Residuales -", best_model_name),
       x = "Residuales",
       y = "Frecuencia") +
  theme_minimal()

p4 <- ggplot(predictions, aes(x = fitted, y = abs_residuals)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(title = paste("Residuales Absolutos vs Ajustados -", best_model_name),
       x = "Valores Ajustados (.pred)",
       y = "Valor Absoluto de Residuales") +
  theme_minimal()

grid.arrange(p1, p2, p3, p4, ncol = 2)


```

### 1. Residuales vs Valores Ajustados

* **Qu√© muestra:** Cada punto es un residuo (error real vs predicho) frente al valor predicho para ese punto.
* **C√≥mo interpretarlo:**

  * Idealmente, los puntos deben estar **dispersos al azar alrededor de cero**, sin formar patrones.
  * Si ves **curvas, l√≠neas o embudos**, indica que el modelo no est√° capturando bien la relaci√≥n o que la varianza de los errores no es constante (heterocedasticidad).
  * Una banda horizontal y dispersa indica que el modelo es adecuado en este sentido.

---

### 2. QQ-Plot de Residuales

* **Qu√© muestra:** Compara la distribuci√≥n de los residuos con una distribuci√≥n normal te√≥rica.
* **C√≥mo interpretarlo:**

  * Si los puntos caen aproximadamente sobre la l√≠nea diagonal, los residuos se comportan como si vinieran de una distribuci√≥n normal, lo que es un supuesto importante para inferencias cl√°sicas.
  * Desviaciones fuertes (curvas o puntos alejados) indican que los residuos no son normales, lo que puede afectar la validez de tests estad√≠sticos y de confianza.

---

### 3. Histograma de Residuales

* **Qu√© muestra:** Distribuci√≥n de la frecuencia de los residuos.
* **C√≥mo interpretarlo:**

  * Idealmente, debe tener forma de campana, sim√©trica y centrada en cero.
  * Si hay sesgos (asimetr√≠a), m√∫ltiples picos o colas largas, indica que los residuos no son normales.
  * Tambi√©n ayuda a detectar valores at√≠picos o errores sistem√°ticos.

---

### 4. Residuales Absolutos vs Valores Ajustados

* **Qu√© muestra:** El valor absoluto de los residuos (es decir, el tama√±o del error sin importar el signo) en funci√≥n de los valores predichos.
* **C√≥mo interpretarlo:**

  * Busca patrones en la variabilidad de los residuos.
  * Si la dispersi√≥n aumenta o disminuye con los valores predichos (forma de embudo, por ejemplo), significa **heterocedasticidad**, es decir, la varianza de los errores no es constante.
  * Esto puede indicar que el modelo necesita transformaciones o modelos m√°s complejos para ajustarse bien.

